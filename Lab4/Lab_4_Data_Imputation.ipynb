{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab_4_Data_Imputation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhtOdxzd1ppr"
      },
      "source": [
        "# Lab 4: Data Imputation using an Autoencoder\n",
        "\n",
        "**Deadline**: Mon, March 01, 5:00pm\n",
        "\n",
        "**Late Penalty**: There is a penalty-free grace period of one hour past the deadline. Any work that is submitted between 1 hour and 24 hours past the deadline will receive a 20% grade deduction. No other late work is accepted. Quercus submission time will be used, not your local computer time. You can submit your labs as many times as you want before the deadline, so please submit often and early.\n",
        "\n",
        "**TA**: Chris Lucasius <christopher.lucasius@mail.utoronto.ca>\n",
        "\n",
        "In this lab, you will build and train an autoencoder to impute (or \"fill in\") missing data. \n",
        "\n",
        "We will be using the\n",
        "Adult Data Set provided by the UCI Machine Learning Repository [1], available \n",
        "at https://archive.ics.uci.edu/ml/datasets/adult.\n",
        "The data set contains census record files of adults, including their\n",
        "age, martial status, the type of work they do, and other features. \n",
        "\n",
        "Normally, people use this data set to build a supervised classification\n",
        "model to classify whether a person is a high income earner.\n",
        "We will not use the dataset for this original intended purpose.\n",
        "\n",
        "Instead, we will perform the task of imputing (or \"filling in\") missing values in the dataset. For example,\n",
        "we may be missing one person's martial status, and another person's age, and\n",
        "a third person's level of education. Our model will predict the missing features \n",
        "based on the information that we do have about each person.\n",
        "\n",
        "We will use a variation of a denoising autoencoder to solve this data imputation\n",
        "problem. Our autoencoder will be trained using inputs that have one categorical feature artificially\n",
        "removed, and the goal of the autoencoder is to correctly reconstruct all features,\n",
        "including the one removed from the input.\n",
        "\n",
        "In the process, you are expected to learn to:\n",
        "\n",
        "1. Clean and process continuous and categorical data for machine learning.\n",
        "2. Implement an autoencoder that takes continuous and categorical (one-hot) inputs.\n",
        "3. Tune the hyperparameters of an autoencoder.\n",
        "4. Use baseline models to help interpret model performance.\n",
        "\n",
        "[1] Dua, D. and Karra Taniskidou, E. (2017). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science.\n",
        "\n",
        "\n",
        "### What to submit\n",
        "\n",
        "Submit a PDF file containing all your code, outputs, and write-up. You can produce a PDF of your Google Colab file by going to File > Print and then save as PDF. The Colab instructions have more information (.html files are also acceptable).\n",
        "\n",
        "Do not submit any other files produced by your code.\n",
        "\n",
        "Include a link to your colab file in your submission.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbnrp2ig1pps"
      },
      "source": [
        "## Colab Link\n",
        "\n",
        "Include a link to your Colab file here. If you would like the TA to look at your\n",
        "Colab file in case your solutions are cut off, **please make sure that your Colab\n",
        "file is publicly accessible at the time of submission**.\n",
        "\n",
        "Colab Link: https://drive.google.com/file/d/1QvJRw67Om5K8_q2vL8LC-l46bOnn-YYL/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUojRzcomeE_"
      },
      "source": [
        "%%shell\n",
        "jupyter nbconvert --to html /Lab_3_Gesture_Recognition.ipynb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "z3p8N43E1ppt"
      },
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import torch.utils.data\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ROwtHcz1ppx"
      },
      "source": [
        "## Part 0\n",
        "\n",
        "We will be using a package called `pandas` for this assignment. \n",
        "\n",
        "If you are using Colab, `pandas` should already be available.\n",
        "If you are using your own computer,\n",
        "installation instructions for `pandas` are available here: \n",
        "https://pandas.pydata.org/pandas-docs/stable/install.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "IXQ7BP151ppz"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqXihb4Q1pp2"
      },
      "source": [
        "# Part 1. Data Cleaning [15 pt]\n",
        "\n",
        "The adult.data file is available at `https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data`\n",
        "\n",
        "The function `pd.read_csv` loads the adult.data file into a pandas dataframe.\n",
        "You can read about the pandas documentation for `pd.read_csv` at\n",
        "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "EOMItFKn1pp3"
      },
      "source": [
        "header = ['age', 'work', 'fnlwgt', 'edu', 'yredu', 'marriage', 'occupation',\n",
        " 'relationship', 'race', 'sex', 'capgain', 'caploss', 'workhr', 'country']\n",
        "df = pd.read_csv(\n",
        "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\",\n",
        "    names=header,\n",
        "    index_col=False)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62Ot405q1pp5",
        "scrolled": true,
        "outputId": "5e18a0e1-3215-4010-b5e8-1b17c84bc1de"
      },
      "source": [
        "df.shape # there are 32561 rows (records) in the data frame, and 14 columns (features)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32561, 14)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tr7YG-QY1pp8"
      },
      "source": [
        "### Part (a) Continuous Features [3 pt]\n",
        "\n",
        "For each of the columns `[\"age\", \"yredu\", \"capgain\", \"caploss\", \"workhr\"]`, report the minimum, maximum, and average value across the dataset. \n",
        "\n",
        "Then, normalize each of the features `[\"age\", \"yredu\", \"capgain\", \"caploss\", \"workhr\"]`\n",
        "so that their values are always between 0 and 1.\n",
        "Make sure that you are actually modifying the dataframe `df`. \n",
        "\n",
        "Like numpy arrays and torch tensors, \n",
        "pandas data frames can be sliced. For example, we can\n",
        "display the first 3 rows of the data frame (3 records) below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "9evSLsSa1pp9",
        "scrolled": false,
        "outputId": "700e8e93-1839-4652-d861-fb197eb26ea6"
      },
      "source": [
        "df[:3] # show the first 3 records"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>work</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>edu</th>\n",
              "      <th>yredu</th>\n",
              "      <th>marriage</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>sex</th>\n",
              "      <th>capgain</th>\n",
              "      <th>caploss</th>\n",
              "      <th>workhr</th>\n",
              "      <th>country</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>39</td>\n",
              "      <td>State-gov</td>\n",
              "      <td>77516</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>2174</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50</td>\n",
              "      <td>Self-emp-not-inc</td>\n",
              "      <td>83311</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>United-States</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>38</td>\n",
              "      <td>Private</td>\n",
              "      <td>215646</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Divorced</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age               work  fnlwgt  ... caploss  workhr         country\n",
              "0   39          State-gov   77516  ...       0      40   United-States\n",
              "1   50   Self-emp-not-inc   83311  ...       0      13   United-States\n",
              "2   38            Private  215646  ...       0      40   United-States\n",
              "\n",
              "[3 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBOojI6W1pqA"
      },
      "source": [
        "Alternatively, we can slice based on column names, \n",
        "for example `df[\"race\"]`, `df[\"hr\"]`, or even index multiple columns \n",
        "like below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "4v6pp73A1pqB",
        "outputId": "56bb441c-bc68-4698-f4be-3198e7054717"
      },
      "source": [
        "subdf = df[[\"age\", \"yredu\", \"capgain\", \"caploss\", \"workhr\"]]\n",
        "subdf[:3] # show the first 3 records"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>yredu</th>\n",
              "      <th>capgain</th>\n",
              "      <th>caploss</th>\n",
              "      <th>workhr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>39</td>\n",
              "      <td>13</td>\n",
              "      <td>2174</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>38</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age  yredu  capgain  caploss  workhr\n",
              "0   39     13     2174        0      40\n",
              "1   50     13        0        0      13\n",
              "2   38      9        0        0      40"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Nru2P0E1pqD"
      },
      "source": [
        "Numpy works nicely with pandas, like below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXrS6tjp1pqE",
        "outputId": "d3222ccb-0a42-4f06-87ee-afd0f1d5c26f"
      },
      "source": [
        "np.sum(subdf[\"caploss\"])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2842700"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mv5mbxDM1pqH"
      },
      "source": [
        "Just like numpy arrays, you can modify\n",
        "entire columns of data rather than one scalar element at a time.\n",
        "For example, the code  \n",
        "\n",
        "`df[\"age\"] = df[\"age\"] + 1` \n",
        "\n",
        "would increment everyone's age by 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "k5rlWD7-1pqH",
        "outputId": "489a7f21-0c3f-439f-eca5-c058ea40c669"
      },
      "source": [
        "print(\"age: \", \"max = \", (df[\"age\"]).max(), \",min = \", (df[\"age\"]).min(), \",avg = \", (df[\"age\"]).mean())\n",
        "print(\"yredu: \", \"max = \", (df[\"yredu\"]).max(), \",min = \", (df[\"yredu\"]).min(), \",avg = \", (df[\"yredu\"]).mean())\n",
        "print(\"capgain: \", \"max = \", (df[\"capgain\"]).max(), \",min = \", (df[\"capgain\"]).min(), \",avg = \", (df[\"capgain\"]).mean())\n",
        "print(\"caploss: \", \"max = \", (df[\"caploss\"]).max(), \",min = \", (df[\"caploss\"]).min(), \",avg = \", (df[\"caploss\"]).mean())\n",
        "print(\"workhr: \", \"max = \", (df[\"workhr\"]).max(), \",min = \", (df[\"workhr\"]).min(), \",avg = \", (df[\"workhr\"]).mean())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "age:  max =  90 ,min =  17 ,avg =  38.58164675532078\n",
            "yredu:  max =  16 ,min =  1 ,avg =  10.0806793403151\n",
            "capgain:  max =  99999 ,min =  0 ,avg =  1077.6488437087312\n",
            "caploss:  max =  4356 ,min =  0 ,avg =  87.303829734959\n",
            "workhr:  max =  99 ,min =  1 ,avg =  40.437455852092995\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G830WnOHAlzR"
      },
      "source": [
        "#normalizing using equation; z = (x - min)/(max - min)\n",
        "df[\"age\"] = (df[\"age\"]-(df[\"age\"]).min()) / ((df[\"age\"]).max() - (df[\"age\"]).min())\n",
        "df[\"yredu\"] = (df[\"yredu\"]-(df[\"yredu\"]).min()) / ((df[\"yredu\"]).max() - (df[\"yredu\"]).min())\n",
        "df[\"capgain\"] = (df[\"capgain\"]-(df[\"capgain\"]).min()) / ((df[\"capgain\"]).max() - (df[\"capgain\"]).min())\n",
        "df[\"caploss\"] = (df[\"caploss\"]-(df[\"caploss\"]).min()) / ((df[\"caploss\"]).max() - (df[\"caploss\"]).min())\n",
        "df[\"workhr\"] = (df[\"workhr\"]-(df[\"workhr\"]).min()) / ((df[\"workhr\"]).max() - (df[\"workhr\"]).min())"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbfMly4R1pqK"
      },
      "source": [
        "### Part (b) Categorical Features [1 pt]\n",
        "\n",
        "What percentage of people in our data set are male? Note that the data labels all have an unfortunate space in the beginning, e.g. \" Male\" instead of \"Male\".\n",
        "\n",
        "What percentage of people in our data set are female?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjAjcsB_1pqK",
        "outputId": "bf319307-596d-41a2-c1e4-49e197804eba"
      },
      "source": [
        "# hint: you can do something like this in pandas\n",
        "print(\"number of male =\",sum(df[\"sex\"] == \" Male\"))\n",
        "print(\"number of female =\",sum(df[\"sex\"] == \" Female\"))\n",
        "\n",
        "print(\"percentage of people in our data set are female =\", (sum(df[\"sex\"] == \" Female\")/(sum(df[\"sex\"] == \" Male\")+sum(df[\"sex\"] == \" Female\")))*100, \"%\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of male = 21790\n",
            "number of female = 10771\n",
            "percentage of people in our data set are female = 33.07945087681583 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGVw7pqL1pqN"
      },
      "source": [
        "### Part (c) [2 pt]\n",
        "\n",
        "Before proceeding, we will modify our data frame in a couple more ways:\n",
        "\n",
        "1. We will restrict ourselves to using a subset of the features (to simplify our autoencoder)\n",
        "2. We will remove any records (rows) already containing missing values, and store them in a second dataframe. We will only use records without missing values to train our autoencoder.\n",
        "\n",
        "Both of these steps are done for you, below.\n",
        "\n",
        "How many records contained missing features? What percentage of records were removed?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "z6ewPUdv1pqO"
      },
      "source": [
        "contcols = [\"age\", \"yredu\", \"capgain\", \"caploss\", \"workhr\"]\n",
        "catcols = [\"work\", \"marriage\", \"occupation\", \"edu\", \"relationship\", \"sex\"]\n",
        "features = contcols + catcols\n",
        "df = df[features]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "fjdVll5a1pqQ"
      },
      "source": [
        "missing = pd.concat([df[c] == \" ?\" for c in catcols], axis=1).any(axis=1)\n",
        "df_with_missing = df[missing]\n",
        "df_not_missing = df[~missing]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvPyLQyQCYwm",
        "outputId": "0a99b8c5-5e8a-472c-8f42-5f1579ce665e"
      },
      "source": [
        "print(\"number of records =\", len(df))\n",
        "print(\"number of records with missing features =\", len(df_with_missing))\n",
        "\n",
        "print(\"percentage of records removed =\", (len(df_with_missing)/len(df))*100, \"%\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of records = 32561\n",
            "number of records with missing features = 1843\n",
            "percentage of records removed = 5.660145572924664 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuEpndTQ1pqU"
      },
      "source": [
        "### Part (d) One-Hot Encoding [1 pt]\n",
        "\n",
        "What are all the possible values of the feature \"work\" in `df_not_missing`? You may find the Python function `set` useful."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "iKFh4owE1pqV",
        "outputId": "68f7ce57-afa3-4fff-de5b-8f7d87074760"
      },
      "source": [
        "print(set(df_not_missing[\"work\"]))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{' Private', ' Self-emp-not-inc', ' Local-gov', ' Self-emp-inc', ' State-gov', ' Without-pay', ' Federal-gov'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COv3HaKr1pqY"
      },
      "source": [
        "We will be using a one-hot encoding to represent each of the categorical variables.\n",
        "Our autoencoder will be trained using these one-hot encodings.\n",
        "\n",
        "We will use the pandas function `get_dummies` to produce one-hot encodings\n",
        "for all of the categorical variables in `df_not_missing`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "eKlSYmJg1pqZ"
      },
      "source": [
        "data = pd.get_dummies(df_not_missing)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "collapsed": true,
        "id": "3y7nTZ7H1pqb",
        "scrolled": true,
        "outputId": "4738b024-b1cd-4b94-d546-c1bcddea322e"
      },
      "source": [
        "data[:3]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>yredu</th>\n",
              "      <th>capgain</th>\n",
              "      <th>caploss</th>\n",
              "      <th>workhr</th>\n",
              "      <th>work_ Federal-gov</th>\n",
              "      <th>work_ Local-gov</th>\n",
              "      <th>work_ Private</th>\n",
              "      <th>work_ Self-emp-inc</th>\n",
              "      <th>work_ Self-emp-not-inc</th>\n",
              "      <th>work_ State-gov</th>\n",
              "      <th>work_ Without-pay</th>\n",
              "      <th>marriage_ Divorced</th>\n",
              "      <th>marriage_ Married-AF-spouse</th>\n",
              "      <th>marriage_ Married-civ-spouse</th>\n",
              "      <th>marriage_ Married-spouse-absent</th>\n",
              "      <th>marriage_ Never-married</th>\n",
              "      <th>marriage_ Separated</th>\n",
              "      <th>marriage_ Widowed</th>\n",
              "      <th>occupation_ Adm-clerical</th>\n",
              "      <th>occupation_ Armed-Forces</th>\n",
              "      <th>occupation_ Craft-repair</th>\n",
              "      <th>occupation_ Exec-managerial</th>\n",
              "      <th>occupation_ Farming-fishing</th>\n",
              "      <th>occupation_ Handlers-cleaners</th>\n",
              "      <th>occupation_ Machine-op-inspct</th>\n",
              "      <th>occupation_ Other-service</th>\n",
              "      <th>occupation_ Priv-house-serv</th>\n",
              "      <th>occupation_ Prof-specialty</th>\n",
              "      <th>occupation_ Protective-serv</th>\n",
              "      <th>occupation_ Sales</th>\n",
              "      <th>occupation_ Tech-support</th>\n",
              "      <th>occupation_ Transport-moving</th>\n",
              "      <th>edu_ 10th</th>\n",
              "      <th>edu_ 11th</th>\n",
              "      <th>edu_ 12th</th>\n",
              "      <th>edu_ 1st-4th</th>\n",
              "      <th>edu_ 5th-6th</th>\n",
              "      <th>edu_ 7th-8th</th>\n",
              "      <th>edu_ 9th</th>\n",
              "      <th>edu_ Assoc-acdm</th>\n",
              "      <th>edu_ Assoc-voc</th>\n",
              "      <th>edu_ Bachelors</th>\n",
              "      <th>edu_ Doctorate</th>\n",
              "      <th>edu_ HS-grad</th>\n",
              "      <th>edu_ Masters</th>\n",
              "      <th>edu_ Preschool</th>\n",
              "      <th>edu_ Prof-school</th>\n",
              "      <th>edu_ Some-college</th>\n",
              "      <th>relationship_ Husband</th>\n",
              "      <th>relationship_ Not-in-family</th>\n",
              "      <th>relationship_ Other-relative</th>\n",
              "      <th>relationship_ Own-child</th>\n",
              "      <th>relationship_ Unmarried</th>\n",
              "      <th>relationship_ Wife</th>\n",
              "      <th>sex_ Female</th>\n",
              "      <th>sex_ Male</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.301370</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.02174</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.397959</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.452055</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.122449</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.287671</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.397959</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        age     yredu  capgain  ...  relationship_ Wife  sex_ Female  sex_ Male\n",
              "0  0.301370  0.800000  0.02174  ...                   0            0          1\n",
              "1  0.452055  0.800000  0.00000  ...                   0            0          1\n",
              "2  0.287671  0.533333  0.00000  ...                   0            0          1\n",
              "\n",
              "[3 rows x 57 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwjDg1uM1pqe"
      },
      "source": [
        "### Part (e) One-Hot Encoding [2 pt]\n",
        "\n",
        "The dataframe `data` contains the cleaned and normalized data that we will use to train our denoising autoencoder.\n",
        "\n",
        "How many **columns** (features) are in the dataframe `data`?\n",
        "\n",
        "Briefly explain where that number come from."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "yjZ5N0Tl1pqf",
        "outputId": "64f11c21-9550-487b-9279-a9f3b6dfe2d8"
      },
      "source": [
        "print(\"number of columns(features) in data =\", len(data.columns))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of columns(features) in data = 57\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C93fUuacEN3K"
      },
      "source": [
        "Number of columns were generated from the get_dummies function where it transfered strings in the data to 0 and 1 which made multiple columns for one columns in the original dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEJ0Ci3l1pqh"
      },
      "source": [
        "### Part (f) One-Hot Conversion [3 pt]\n",
        "\n",
        "We will convert the pandas data frame `data` into numpy, so that\n",
        "it can be further converted into a PyTorch tensor.\n",
        "However, in doing so, we lose the column label information that\n",
        "a panda data frame automatically stores.\n",
        "\n",
        "Complete the function `get_categorical_value` that will return\n",
        "the named value of a feature given a one-hot embedding.\n",
        "You may find the global variables `cat_index` and `cat_values`\n",
        "useful. (Display them and figure out what they are first.)\n",
        "\n",
        "We will need this function in the next part of the lab\n",
        "to interpret our autoencoder outputs. So, the input\n",
        "to our function `get_categorical_values` might not \n",
        "actually be \"one-hot\" -- the input may instead \n",
        "contain real-valued predictions from our neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "ZmovX6gu1pqi"
      },
      "source": [
        "datanp = data.values.astype(np.float32)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "YRIa5MBd1pql"
      },
      "source": [
        "cat_index = {}  # Mapping of feature -> start index of feature in a record\n",
        "cat_values = {} # Mapping of feature -> list of categorical values the feature can take\n",
        "\n",
        "# build up the cat_index and cat_values dictionary\n",
        "for i, header in enumerate(data.keys()):\n",
        "    if \"_\" in header: # categorical header\n",
        "        feature, value = header.split()\n",
        "        feature = feature[:-1] # remove the last char; it is always an underscore\n",
        "        if feature not in cat_index:\n",
        "            cat_index[feature] = i\n",
        "            cat_values[feature] = [value]\n",
        "        else:\n",
        "            cat_values[feature].append(value)\n",
        "\n",
        "def get_onehot(record, feature):\n",
        "    \"\"\"\n",
        "    Return the portion of `record` that is the one-hot encoding\n",
        "    of `feature`. For example, since the feature \"work\" is stored\n",
        "    in the indices [5:12] in each record, calling `get_range(record, \"work\")`\n",
        "    is equivalent to accessing `record[5:12]`.\n",
        "    \n",
        "    Args:\n",
        "        - record: a numpy array representing one record, formatted\n",
        "                  the same way as a row in `data.np`\n",
        "        - feature: a string, should be an element of `catcols`\n",
        "    \"\"\"\n",
        "    start_index = cat_index[feature]\n",
        "    stop_index = cat_index[feature] + len(cat_values[feature])\n",
        "    return record[start_index:stop_index]\n",
        "\n",
        "def get_categorical_value(onehot, feature):\n",
        "    \"\"\"\n",
        "    Return the categorical value name of a feature given\n",
        "    a one-hot vector representing the feature.\n",
        "    \n",
        "    Args:\n",
        "        - onehot: a numpy array one-hot representation of the feature\n",
        "        - feature: a string, should be an element of `catcols`\n",
        "        \n",
        "    Examples:\n",
        "    \n",
        "    >>> get_categorical_value(np.array([0., 0., 0., 0., 0., 1., 0.]), \"work\")\n",
        "    'State-gov'\n",
        "    >>> get_categorical_value(np.array([0.1, 0., 1.1, 0.2, 0., 1., 0.]), \"work\")\n",
        "    'Private'\n",
        "    \"\"\"\n",
        "    # <----- TODO: WRITE YOUR CODE HERE ----->\n",
        "    # You may find the variables `cat_index` and `cat_values` \n",
        "    # (created above) useful.\n",
        "    return cat_values[feature][np.argmax(onehot)]"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzIdA7SeF7ef",
        "outputId": "4fc45152-d3f4-49cc-bfcd-b20cfcc1efc1"
      },
      "source": [
        "print(cat_index)\n",
        "print(cat_values)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'work': 5, 'marriage': 12, 'occupation': 19, 'edu': 33, 'relationship': 49, 'sex': 55}\n",
            "{'work': ['Federal-gov', 'Local-gov', 'Private', 'Self-emp-inc', 'Self-emp-not-inc', 'State-gov', 'Without-pay'], 'marriage': ['Divorced', 'Married-AF-spouse', 'Married-civ-spouse', 'Married-spouse-absent', 'Never-married', 'Separated', 'Widowed'], 'occupation': ['Adm-clerical', 'Armed-Forces', 'Craft-repair', 'Exec-managerial', 'Farming-fishing', 'Handlers-cleaners', 'Machine-op-inspct', 'Other-service', 'Priv-house-serv', 'Prof-specialty', 'Protective-serv', 'Sales', 'Tech-support', 'Transport-moving'], 'edu': ['10th', '11th', '12th', '1st-4th', '5th-6th', '7th-8th', '9th', 'Assoc-acdm', 'Assoc-voc', 'Bachelors', 'Doctorate', 'HS-grad', 'Masters', 'Preschool', 'Prof-school', 'Some-college'], 'relationship': ['Husband', 'Not-in-family', 'Other-relative', 'Own-child', 'Unmarried', 'Wife'], 'sex': ['Female', 'Male']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "T_XXxZdh1pqv"
      },
      "source": [
        "# more useful code, used during training, that depends on the function\n",
        "# you write above\n",
        "\n",
        "def get_feature(record, feature):\n",
        "    \"\"\"\n",
        "    Return the categorical feature value of a record\n",
        "    \"\"\"\n",
        "    onehot = get_onehot(record, feature)\n",
        "    return get_categorical_value(onehot, feature)\n",
        "\n",
        "def get_features(record):\n",
        "    \"\"\"\n",
        "    Return a dictionary of all categorical feature values of a record\n",
        "    \"\"\"\n",
        "    return { f: get_feature(record, f) for f in catcols }"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_5ZZR_J1pqy"
      },
      "source": [
        "### Part (g) Train/Test Split [3 pt]\n",
        "\n",
        "Randomly split the data into approximately 70% training, 15% validation and 15% test.\n",
        "\n",
        "Report the number of items in your training, validation, and test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "TE_fTJJf1pqz",
        "outputId": "c22ba367-84ac-4364-d673-114215090250"
      },
      "source": [
        "# set the numpy seed for reproducibility\n",
        "# https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.seed.html\n",
        "np.random.seed(50)\n",
        "\n",
        "# todo\n",
        "np.random.shuffle(datanp)\n",
        "\n",
        "train_end = int(datanp.shape[0] * 0.7)\n",
        "val_end = int(datanp.shape[0] * 0.85)\n",
        "test_end = int(datanp.shape[0] * 1)\n",
        "\n",
        "train_dataset = datanp[:train_end]\n",
        "val_dataset = datanp[train_end:val_end]\n",
        "test_dataset = datanp[val_end:test_end]\n",
        "\n",
        "print(\"size of training dataset =\", len(train_dataset))\n",
        "print(\"size of validation dataset =\", len(val_dataset))\n",
        "print(\"size of test dataset =\", len(test_dataset))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "size of training dataset = 21502\n",
            "size of validation dataset = 4608\n",
            "size of test dataset = 4608\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9wJAKOI1pq3"
      },
      "source": [
        "## Part 2. Model Setup [5 pt]\n",
        "\n",
        "### Part (a) [4 pt]\n",
        "\n",
        "Design a fully-connected autoencoder by modifying the `encoder` and `decoder`\n",
        "below.\n",
        "\n",
        "The input to this autoencoder will be the features of the `data`, with\n",
        "one categorical feature recorded as \"missing\". The output of the autoencoder\n",
        "should be the reconstruction of the same features, but with the missing\n",
        "value filled in.\n",
        "\n",
        "**Note**: Do not reduce the dimensionality of the input too much!\n",
        "The output of your embedding is expected to contain information \n",
        "about ~11 features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "f3F--tdn1pq3"
      },
      "source": [
        "from torch import nn\n",
        "\n",
        "class AutoEncoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AutoEncoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(57, 37), # TODO -- FILL OUT THE CODE HERE!\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(37, 27),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(27, 17)\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(17, 27), # TODO -- FILL OUT THE CODE HERE!\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(27, 37),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(37, 57),\n",
        "            nn.Sigmoid() # get to the range (0, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuEzTSAv1pq6"
      },
      "source": [
        "### Part (b) [1 pt]\n",
        "\n",
        "Explain why there is a sigmoid activation in the last step of the decoder.\n",
        "\n",
        "(**Note**: the values inside the data frame `data` and the training code in Part 3 might be helpful.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiIriPpSJ9bT"
      },
      "source": [
        "Since we nomalized the data, the values are between 0 to 1. The output of the decoder should be between 0 to 1 because the decoder is reconstructing the inputs. \n",
        "Sigmoid activation function forces the output to be between 0 to 1 which is why we need this in the last step of the decoder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYwqFWVl1pq8"
      },
      "source": [
        "## Part 3. Training [18] \n",
        "\n",
        "### Part (a) [6 pt]\n",
        "\n",
        "We will train our autoencoder in the following way:\n",
        "\n",
        "- In each iteration, we will hide one of the categorical features using the `zero_out_random_features` function\n",
        "- We will pass the data with one missing feature through the autoencoder, and obtain a reconstruction\n",
        "- We will check how close the reconstruction is compared to the original data -- including the value of the missing feature\n",
        "\n",
        "Complete the code to train the autoencoder, and plot the training and validation loss every few iterations.\n",
        "You may also want to plot training and validation \"accuracy\" every few iterations, as we will define in\n",
        "part (b). You may also want to checkpoint your model every few iterations or epochs.\n",
        "\n",
        "Use `nn.MSELoss()` as your loss function. (Side note: you might recognize that this loss function is not\n",
        "ideal for this problem, but we will use it anyway.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "IDQA_-dS1pq9"
      },
      "source": [
        "def zero_out_feature(records, feature):\n",
        "    \"\"\" Set the feature missing in records, by setting the appropriate\n",
        "    columns of records to 0\n",
        "    \"\"\"\n",
        "    start_index = cat_index[feature]\n",
        "    stop_index = cat_index[feature] + len(cat_values[feature])\n",
        "    records[:, start_index:stop_index] = 0\n",
        "    return records\n",
        "\n",
        "def zero_out_random_feature(records):\n",
        "    \"\"\" Set one random feature missing in records, by setting the \n",
        "    appropriate columns of records to 0\n",
        "    \"\"\"\n",
        "    return zero_out_feature(records, random.choice(catcols))\n",
        "\n",
        "def train(model, train_loader, valid_loader, batch_size=64, num_epochs=5, learning_rate=1e-4):\n",
        "    \"\"\" Training loop. You should update this.\"\"\"\n",
        "    torch.manual_seed(42)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    iters, train_losses, val_losses, train_acc, val_acc = [], [], [], [], []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for data in train_loader:\n",
        "            datam = zero_out_random_feature(data.clone()) # zero out one categorical feature\n",
        "            recon = model(datam)\n",
        "            train_loss = criterion(recon, data)\n",
        "            train_loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        for data in val_loader:\n",
        "            datam = zero_out_random_feature(data.clone()) # zero out one categorical feature\n",
        "            recon = model(datam)\n",
        "            val_loss = criterion(recon, data)\n",
        "\n",
        "        iters.append(epoch)\n",
        "        train_losses.append(float(train_loss)/batch_size)             # compute *average* loss\n",
        "        val_losses.append(float(val_loss)/batch_size)             # compute *average* loss\n",
        "        train_acc.append(get_accuracy(model, train_loader)) # compute training accuracy \n",
        "        val_acc.append(get_accuracy(model, val_loader))  # compute validation accuracy\n",
        "\n",
        "        #print accuracy for each epoch\n",
        "        print(\"epoch:\", epoch+1, \"train_accuracy: \", train_acc[epoch], \"val_accuracy: \", val_acc[epoch])\n",
        "\n",
        "    # plotting\n",
        "    plt.title(\"Training Curve\")\n",
        "    plt.plot(iters, train_losses, label=\"Train\")\n",
        "    plt.plot(iters, val_losses, label=\"Validation\")\n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.show()\n",
        "\n",
        "    plt.title(\"Training Curve\")\n",
        "    plt.plot(iters, train_acc, label=\"Train\")\n",
        "    plt.plot(iters, val_acc, label=\"Validation\")\n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.ylabel(\"Training Accuracy\")\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()\n",
        "\n",
        "    print(\"Final Training Accuracy: {}\".format(train_acc[-1]))\n",
        "    print(\"Final Validation Accuracy: {}\".format(val_acc[-1]))\n"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKk01pwx1pq_"
      },
      "source": [
        "### Part (b) [3 pt]\n",
        "\n",
        "While plotting training and validation loss is valuable, loss values are harder to compare\n",
        "than accuracy percentages. It would be nice to have a measure of \"accuracy\" in this problem.\n",
        "\n",
        "Since we will only be imputing missing categorical values, we will define an accuracy measure.\n",
        "For each record and for each categorical feature, we determine whether\n",
        "the model can predict the categorical feature given all the other features of the record.\n",
        "\n",
        "A function `get_accuracy` is written for you. It is up to you to figure out how to\n",
        "use the function. **You don't need to submit anything in this part.**\n",
        "To earn the marks, correctly plot the training and validation accuracy every few \n",
        "iterations as part of your training curve."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "bHWLfCzM1pq_"
      },
      "source": [
        "def get_accuracy(model, data_loader):\n",
        "    \"\"\"Return the \"accuracy\" of the autoencoder model across a data set.\n",
        "    That is, for each record and for each categorical feature, \n",
        "    we determine whether the model can successfully predict the value\n",
        "    of the categorical feature given all the other features of the \n",
        "    record. The returned \"accuracy\" measure is the percentage of times \n",
        "    that our model is successful.\n",
        "        \n",
        "    Args:\n",
        "       - model: the autoencoder model, an instance of nn.Module\n",
        "       - data_loader: an instance of torch.utils.data.DataLoader\n",
        "\n",
        "    Example (to illustrate how get_accuracy is intended to be called.\n",
        "             Depending on your variable naming this code might require\n",
        "             modification.)\n",
        "\n",
        "        >>> model = AutoEncoder()\n",
        "        >>> vdl = torch.utils.data.DataLoader(data_valid, batch_size=256, shuffle=True)\n",
        "        >>> get_accuracy(model, vdl)\n",
        "    \"\"\"\n",
        "    total = 0\n",
        "    acc = 0\n",
        "    for col in catcols:\n",
        "        for item in data_loader: # minibatches\n",
        "            inp = item.detach().numpy()\n",
        "            out = model(zero_out_feature(item.clone(), col)).detach().numpy()\n",
        "            for i in range(out.shape[0]): # record in minibatch\n",
        "                acc += int(get_feature(out[i], col) == get_feature(inp[i], col))\n",
        "                total += 1\n",
        "    return acc / total"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxCTlXoV1prB"
      },
      "source": [
        "### Part (c) [4 pt]\n",
        "\n",
        "Run your updated training code, using reasonable initial hyperparameters.\n",
        "\n",
        "Include your training curve in your submission."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 947
        },
        "collapsed": true,
        "id": "nj5b71l-1prC",
        "outputId": "99dbd7d9-523e-4aad-ada4-f2456fd65307"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "autoencoder = AutoEncoder()\n",
        "\n",
        "train(autoencoder, train_loader, val_loader, num_epochs=20, learning_rate=0.0001)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 1 train_accuracy:  0.44222242892134067 val_accuracy:  0.4416232638888889\n",
            "epoch: 2 train_accuracy:  0.4556010293616098 val_accuracy:  0.4544994212962963\n",
            "epoch: 3 train_accuracy:  0.4598254425944873 val_accuracy:  0.4585503472222222\n",
            "epoch: 4 train_accuracy:  0.4621973149784516 val_accuracy:  0.46064814814814814\n",
            "epoch: 5 train_accuracy:  0.4645381824946517 val_accuracy:  0.4625651041666667\n",
            "epoch: 6 train_accuracy:  0.46563885530028215 val_accuracy:  0.4652777777777778\n",
            "epoch: 7 train_accuracy:  0.5114485474219452 val_accuracy:  0.5112485532407407\n",
            "epoch: 8 train_accuracy:  0.5430037515889995 val_accuracy:  0.5436921296296297\n",
            "epoch: 9 train_accuracy:  0.5562738349920937 val_accuracy:  0.5554832175925926\n",
            "epoch: 10 train_accuracy:  0.561490403993427 val_accuracy:  0.5597149884259259\n",
            "epoch: 11 train_accuracy:  0.5650792174371376 val_accuracy:  0.5648148148148148\n",
            "epoch: 12 train_accuracy:  0.5636684959538648 val_accuracy:  0.5635489004629629\n",
            "epoch: 13 train_accuracy:  0.565908597649831 val_accuracy:  0.5656828703703703\n",
            "epoch: 14 train_accuracy:  0.5671642947942827 val_accuracy:  0.5674913194444444\n",
            "epoch: 15 train_accuracy:  0.5660946268564164 val_accuracy:  0.5669849537037037\n",
            "epoch: 16 train_accuracy:  0.5674898459058072 val_accuracy:  0.5676721643518519\n",
            "epoch: 17 train_accuracy:  0.5663116609307661 val_accuracy:  0.5668402777777778\n",
            "epoch: 18 train_accuracy:  0.5686835333147304 val_accuracy:  0.5692274305555556\n",
            "epoch: 19 train_accuracy:  0.5714352153288066 val_accuracy:  0.5703848379629629\n",
            "epoch: 20 train_accuracy:  0.5737993364958298 val_accuracy:  0.5725549768518519\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Final Training Accuracy: 0.5737993364958298\n",
            "Final Validation Accuracy: 0.5725549768518519\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9xTwIf51prF"
      },
      "source": [
        "### Part (d) [5 pt]\n",
        "\n",
        "Tune your hyperparameters, training at least 4 different models (4 sets of hyperparameters).\n",
        "\n",
        "Do not include all your training curves. Instead, explain what hyperparameters\n",
        "you tried, what their effect was, and what your thought process was as you \n",
        "chose the next set of hyperparameters to try."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "PhTKt9iL1prG"
      },
      "source": [
        "def train_no_curves(model, train_loader, valid_loader, batch_size=64, num_epochs=5, learning_rate=1e-4):\n",
        "    \"\"\" Training loop. You should update this.\"\"\"\n",
        "    torch.manual_seed(42)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    iters, train_losses, val_losses, train_acc, val_acc = [], [], [], [], []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for data in train_loader:\n",
        "            datam = zero_out_random_feature(data.clone()) # zero out one categorical feature\n",
        "            recon = model(datam)\n",
        "            train_loss = criterion(recon, data)\n",
        "            train_loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        for data in val_loader:\n",
        "            datam = zero_out_random_feature(data.clone()) # zero out one categorical feature\n",
        "            recon = model(datam)\n",
        "            val_loss = criterion(recon, data)\n",
        "\n",
        "        iters.append(epoch)\n",
        "        train_losses.append(float(train_loss)/batch_size)             # compute *average* loss\n",
        "        val_losses.append(float(val_loss)/batch_size)             # compute *average* loss\n",
        "        train_acc.append(get_accuracy(model, train_loader)) # compute training accuracy \n",
        "        val_acc.append(get_accuracy(model, val_loader))  # compute validation accuracy\n",
        "\n",
        "        #print accuracy for each epoch\n",
        "        print(\"epoch:\", epoch+1, \"train_accuracy: \", train_acc[epoch], \"val_accuracy: \", val_acc[epoch])"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fd9Zle6taFCh",
        "outputId": "c6fe0f6f-a60e-482a-8b81-edb54128146b"
      },
      "source": [
        "#batch_size: 64, num_epochs: 30, lr: 0.0001\n",
        "#Used same parameters from part c, except increased the number of epochs\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "autoencoder = AutoEncoder()\n",
        "\n",
        "train_no_curves(autoencoder, train_loader, val_loader, num_epochs=30, learning_rate=0.0001)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 1 train_accuracy:  0.44222242892134067 val_accuracy:  0.4416232638888889\n",
            "epoch: 2 train_accuracy:  0.45540724893808326 val_accuracy:  0.45417390046296297\n",
            "epoch: 3 train_accuracy:  0.4598331938114284 val_accuracy:  0.4585503472222222\n",
            "epoch: 4 train_accuracy:  0.461856261433045 val_accuracy:  0.46043113425925924\n",
            "epoch: 5 train_accuracy:  0.4646001922301801 val_accuracy:  0.46263744212962965\n",
            "epoch: 6 train_accuracy:  0.4656466065172232 val_accuracy:  0.4650607638888889\n",
            "epoch: 7 train_accuracy:  0.48466034167364275 val_accuracy:  0.48343460648148145\n",
            "epoch: 8 train_accuracy:  0.5388490993085915 val_accuracy:  0.5395326967592593\n",
            "epoch: 9 train_accuracy:  0.5485458717018572 val_accuracy:  0.5487557870370371\n",
            "epoch: 10 train_accuracy:  0.5505069295879453 val_accuracy:  0.5491898148148148\n",
            "epoch: 11 train_accuracy:  0.5638157690757449 val_accuracy:  0.5629340277777778\n",
            "epoch: 12 train_accuracy:  0.563443710662574 val_accuracy:  0.5628978587962963\n",
            "epoch: 13 train_accuracy:  0.5640173007162125 val_accuracy:  0.5640190972222222\n",
            "epoch: 14 train_accuracy:  0.5610020773261402 val_accuracy:  0.5626085069444444\n",
            "epoch: 15 train_accuracy:  0.5583201562645336 val_accuracy:  0.5581958912037037\n",
            "epoch: 16 train_accuracy:  0.5612733699190773 val_accuracy:  0.5602575231481481\n",
            "epoch: 17 train_accuracy:  0.5614128918240163 val_accuracy:  0.5595341435185185\n",
            "epoch: 18 train_accuracy:  0.5611648528819024 val_accuracy:  0.5600766782407407\n",
            "epoch: 19 train_accuracy:  0.5707531082379934 val_accuracy:  0.5688657407407407\n",
            "epoch: 20 train_accuracy:  0.5741558924751186 val_accuracy:  0.5728443287037037\n",
            "epoch: 21 train_accuracy:  0.5767603013673147 val_accuracy:  0.5732060185185185\n",
            "epoch: 22 train_accuracy:  0.5802405977738505 val_accuracy:  0.5775462962962963\n",
            "epoch: 23 train_accuracy:  0.5838914209530897 val_accuracy:  0.5796079282407407\n",
            "epoch: 24 train_accuracy:  0.5851703717483645 val_accuracy:  0.5829716435185185\n",
            "epoch: 25 train_accuracy:  0.5864570737605804 val_accuracy:  0.5833333333333334\n",
            "epoch: 26 train_accuracy:  0.5878135367252658 val_accuracy:  0.5848885995370371\n",
            "epoch: 27 train_accuracy:  0.5880228195826744 val_accuracy:  0.5851417824074074\n",
            "epoch: 28 train_accuracy:  0.592627042445664 val_accuracy:  0.5881438078703703\n",
            "epoch: 29 train_accuracy:  0.5915573745077978 val_accuracy:  0.5880714699074074\n",
            "epoch: 30 train_accuracy:  0.5934564226583574 val_accuracy:  0.58984375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzpGRBfyaH88",
        "outputId": "0b3df308-b0fb-4aee-db11-3ba6f8014896"
      },
      "source": [
        "#results were slightly better than partc, however did not make a huge difference\n",
        "#lowered the learning rate, decreased the batch_size, and decreased the number of epochs\n",
        "#batch_size: 32, num_epochs: 20, lr: 0.001\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "autoencoder = AutoEncoder()\n",
        "\n",
        "train_no_curves(autoencoder, train_loader, val_loader, batch_size=32, num_epochs=20, learning_rate=0.001)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 1 train_accuracy:  0.5777369547018882 val_accuracy:  0.5767867476851852\n",
            "epoch: 2 train_accuracy:  0.5914023501689766 val_accuracy:  0.5910373263888888\n",
            "epoch: 3 train_accuracy:  0.6054398040492357 val_accuracy:  0.6003689236111112\n",
            "epoch: 4 train_accuracy:  0.5911000527082751 val_accuracy:  0.5880353009259259\n",
            "epoch: 5 train_accuracy:  0.6044476482807801 val_accuracy:  0.5997178819444444\n",
            "epoch: 6 train_accuracy:  0.609369671038353 val_accuracy:  0.6032986111111112\n",
            "epoch: 7 train_accuracy:  0.6136793476575823 val_accuracy:  0.6102068865740741\n",
            "epoch: 8 train_accuracy:  0.6078271788670822 val_accuracy:  0.6042028356481481\n",
            "epoch: 9 train_accuracy:  0.6140824109385173 val_accuracy:  0.6085792824074074\n",
            "epoch: 10 train_accuracy:  0.5952392025548011 val_accuracy:  0.5912543402777778\n",
            "epoch: 11 train_accuracy:  0.6173534244876445 val_accuracy:  0.6126302083333334\n",
            "epoch: 12 train_accuracy:  0.6279570892630143 val_accuracy:  0.6231915509259259\n",
            "epoch: 13 train_accuracy:  0.613129011254767 val_accuracy:  0.6095196759259259\n",
            "epoch: 14 train_accuracy:  0.6244070319040089 val_accuracy:  0.6204788773148148\n",
            "epoch: 15 train_accuracy:  0.612090348184665 val_accuracy:  0.6093026620370371\n",
            "epoch: 16 train_accuracy:  0.6358478281090131 val_accuracy:  0.6297381365740741\n",
            "epoch: 17 train_accuracy:  0.6295848448206368 val_accuracy:  0.6268084490740741\n",
            "epoch: 18 train_accuracy:  0.6364679254642979 val_accuracy:  0.6304615162037037\n",
            "epoch: 19 train_accuracy:  0.6352587356214926 val_accuracy:  0.6300998263888888\n",
            "epoch: 20 train_accuracy:  0.6378011347781601 val_accuracy:  0.6339337384259259\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoJO8XAzaIQc",
        "outputId": "bba648a5-d105-46b1-ec9d-3bc650999525"
      },
      "source": [
        "#since the results were improved with the parameters chosen above, \n",
        "#made a small change - decided to increase the number of epochs\n",
        "#batch_size: 32, num_epochs: 30, lr: 0.001\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "autoencoder = AutoEncoder()\n",
        "\n",
        "train_no_curves(autoencoder, train_loader, val_loader, batch_size=32, num_epochs=30, learning_rate=0.001)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 1 train_accuracy:  0.5697144451678914 val_accuracy:  0.5701678240740741\n",
            "epoch: 2 train_accuracy:  0.5909915356711004 val_accuracy:  0.5898799189814815\n",
            "epoch: 3 train_accuracy:  0.6045794189687781 val_accuracy:  0.6027560763888888\n",
            "epoch: 4 train_accuracy:  0.6079977056397855 val_accuracy:  0.6039496527777778\n",
            "epoch: 5 train_accuracy:  0.6119740799305491 val_accuracy:  0.6072771990740741\n",
            "epoch: 6 train_accuracy:  0.6167255759154188 val_accuracy:  0.6137876157407407\n",
            "epoch: 7 train_accuracy:  0.6115787678665551 val_accuracy:  0.6078197337962963\n",
            "epoch: 8 train_accuracy:  0.620004340681487 val_accuracy:  0.6141854745370371\n",
            "epoch: 9 train_accuracy:  0.6140126499860478 val_accuracy:  0.6100983796296297\n",
            "epoch: 10 train_accuracy:  0.6101913000341054 val_accuracy:  0.6069516782407407\n",
            "epoch: 11 train_accuracy:  0.5939680029764673 val_accuracy:  0.5919415509259259\n",
            "epoch: 12 train_accuracy:  0.6039360679626702 val_accuracy:  0.6015263310185185\n",
            "epoch: 13 train_accuracy:  0.6132452795088829 val_accuracy:  0.6102068865740741\n",
            "epoch: 14 train_accuracy:  0.605470808917 val_accuracy:  0.6024305555555556\n",
            "epoch: 15 train_accuracy:  0.5976110749387654 val_accuracy:  0.5960648148148148\n",
            "epoch: 16 train_accuracy:  0.6081837348463709 val_accuracy:  0.6059751157407407\n",
            "epoch: 17 train_accuracy:  0.6130670015192385 val_accuracy:  0.6104962384259259\n",
            "epoch: 18 train_accuracy:  0.6161364834278982 val_accuracy:  0.6123046875\n",
            "epoch: 19 train_accuracy:  0.6162760053328372 val_accuracy:  0.6131727430555556\n",
            "epoch: 20 train_accuracy:  0.6168883514711809 val_accuracy:  0.6123046875\n",
            "epoch: 21 train_accuracy:  0.6114082410938517 val_accuracy:  0.6077112268518519\n",
            "epoch: 22 train_accuracy:  0.6154001178184975 val_accuracy:  0.6119429976851852\n",
            "epoch: 23 train_accuracy:  0.6124624065978359 val_accuracy:  0.6079644097222222\n",
            "epoch: 24 train_accuracy:  0.6213763060800546 val_accuracy:  0.6148726851851852\n",
            "epoch: 25 train_accuracy:  0.6214383158155831 val_accuracy:  0.6178747106481481\n",
            "epoch: 26 train_accuracy:  0.6231668371934393 val_accuracy:  0.6185257523148148\n",
            "epoch: 27 train_accuracy:  0.6263913434409202 val_accuracy:  0.6219618055555556\n",
            "epoch: 28 train_accuracy:  0.6288174743434719 val_accuracy:  0.6238425925925926\n",
            "epoch: 29 train_accuracy:  0.6295848448206368 val_accuracy:  0.6240596064814815\n",
            "epoch: 30 train_accuracy:  0.6246938269308281 val_accuracy:  0.6180555555555556\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ARiu07raItJ",
        "outputId": "bcd6924c-ddbd-4b3d-8349-98c1164cda87"
      },
      "source": [
        "#increased batch size along with the learning rate and decreased number of epochs\n",
        "#batch_size: 64, num_epochs: 20, lr: 0.005\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "best_model = AutoEncoder()\n",
        "\n",
        "train_no_curves(best_model, train_loader, val_loader, batch_size=64, num_epochs=20, learning_rate=0.005)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 1 train_accuracy:  0.5945881003317521 val_accuracy:  0.5910011574074074\n",
            "epoch: 2 train_accuracy:  0.6106796267013921 val_accuracy:  0.6040219907407407\n",
            "epoch: 3 train_accuracy:  0.6168418441695346 val_accuracy:  0.6096643518518519\n",
            "epoch: 4 train_accuracy:  0.5951616903853905 val_accuracy:  0.5916883680555556\n",
            "epoch: 5 train_accuracy:  0.6225002325365082 val_accuracy:  0.6196469907407407\n",
            "epoch: 6 train_accuracy:  0.6136715964406412 val_accuracy:  0.6085431134259259\n",
            "epoch: 7 train_accuracy:  0.6304684835519176 val_accuracy:  0.6255787037037037\n",
            "epoch: 8 train_accuracy:  0.6283446501100672 val_accuracy:  0.6225405092592593\n",
            "epoch: 9 train_accuracy:  0.6283679037608905 val_accuracy:  0.6230830439814815\n",
            "epoch: 10 train_accuracy:  0.638304963879329 val_accuracy:  0.6332465277777778\n",
            "epoch: 11 train_accuracy:  0.6289724986822931 val_accuracy:  0.6236617476851852\n",
            "epoch: 12 train_accuracy:  0.6347471553033827 val_accuracy:  0.6311125578703703\n",
            "epoch: 13 train_accuracy:  0.6313986295848448 val_accuracy:  0.6273148148148148\n",
            "epoch: 14 train_accuracy:  0.6372042910736986 val_accuracy:  0.6352358217592593\n",
            "epoch: 15 train_accuracy:  0.6409248752054072 val_accuracy:  0.6363932291666666\n",
            "epoch: 16 train_accuracy:  0.6422270796515053 val_accuracy:  0.6384910300925926\n",
            "epoch: 17 train_accuracy:  0.6467925464297895 val_accuracy:  0.6416739004629629\n",
            "epoch: 18 train_accuracy:  0.6384754906520324 val_accuracy:  0.6345847800925926\n",
            "epoch: 19 train_accuracy:  0.640118748643537 val_accuracy:  0.6358506944444444\n",
            "epoch: 20 train_accuracy:  0.6302747031283912 val_accuracy:  0.6253978587962963\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxKgIkiMe8Wj"
      },
      "source": [
        "Last set of parameters recorded the best train and validation accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymCsZH291prI"
      },
      "source": [
        "## Part 4. Testing [12 pt]\n",
        "\n",
        "### Part (a) [2 pt]\n",
        "\n",
        "Compute and report the test accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "0OkSbup91prJ",
        "outputId": "779e18cc-4081-4add-f191-80ad3e42051a"
      },
      "source": [
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "test_acc = get_accuracy(best_model, test_loader)\n",
        "\n",
        "print(\"Test Accuracy:\", test_acc)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.6278573495370371\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEe9yt6L1prM"
      },
      "source": [
        "### Part (b) [4 pt]\n",
        "\n",
        "Based on the test accuracy alone, it is difficult to assess whether our model\n",
        "is actually performing well. We don't know whether a high accuracy is due to\n",
        "the simplicity of the problem, or if a poor accuracy is a result of the inherent\n",
        "difficulty of the problem.\n",
        "\n",
        "It is therefore very important to be able to compare our model to at least one\n",
        "alternative. In particular, we consider a simple **baseline**\n",
        "model that is not very computationally expensive. Our neural network\n",
        "should at least outperform this baseline model. If our network is not much\n",
        "better than the baseline, then it is not doing well.\n",
        "\n",
        "For our data imputation problem, consider the following baseline model:\n",
        "to predict a missing feature, the baseline model will look at the **most common value** of the feature in the training set. \n",
        "\n",
        "For example, if the feature \"marriage\" is missing, then this model's prediction will be the most common value for \"marriage\" in the training set, which happens to be \"Married-civ-spouse\".\n",
        "\n",
        "What would be the test accuracy of this baseline model?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "p45VHp011prN",
        "outputId": "f796c30a-6bf4-46a3-f81b-b51d806681df"
      },
      "source": [
        "#most common value model\n",
        "mcv = {}\n",
        "\n",
        "for i in df_not_missing.columns:\n",
        "    mcv[i] = df_not_missing[i].value_counts().idxmax()\n",
        "\n",
        "#baseline acc is when (correct prediction)/total\n",
        "baseline_acc = sum(df_not_missing[\"marriage\"] == mcv[\"marriage\"])/len(df_not_missing)\n",
        "\n",
        "print(\"Baseline model accuracy:\", baseline_acc) "
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Baseline model accuracy: 0.4667947131974738\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlHu0wxh1prP"
      },
      "source": [
        "### Part (c) [1 pt]\n",
        "\n",
        "How does your test accuracy from part (a) compared to your basline test accuracy in part (b)?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O928nGYUiy7c"
      },
      "source": [
        "My model from part (a) performs noticeably better than the baseline(mcv) model from part(b) by comparing the test accuracies in both models. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfQPgu1Q1prS"
      },
      "source": [
        "### Part (d) [1 pt]\n",
        "\n",
        "Look at the first item in your test data. \n",
        "Do you think it is reasonable for a human\n",
        "to be able to guess this person's education level\n",
        "based on their other features? Explain."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "3qbQ1vvT1prT",
        "outputId": "b6c08040-f931-4dba-b527-56dff73d71d7"
      },
      "source": [
        "get_features(test_dataset[0])"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'edu': 'Bachelors',\n",
              " 'marriage': 'Divorced',\n",
              " 'occupation': 'Prof-specialty',\n",
              " 'relationship': 'Not-in-family',\n",
              " 'sex': 'Male',\n",
              " 'work': 'Private'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EljcsCdjotT"
      },
      "source": [
        "Marriage, sex, and relationship does not say much about the person's education level, however it is somewhat reasonable for a human to guess one's education level based on one's work and occupation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_d5uuAY1prZ"
      },
      "source": [
        "### Part (e) [2 pt]\n",
        "\n",
        "What is your model's prediction of this person's education\n",
        "level, given their other features?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "kBY5gKXR1pra",
        "outputId": "c1ee3f90-f9ad-4c0a-e72a-1d5b57ff4482"
      },
      "source": [
        "test_person = torch.from_numpy(test_dataset[0])\n",
        "\n",
        "pred = best_model(test_person)\n",
        "pred = pred.detach().numpy()\n",
        "\n",
        "result = get_feature(pred, \"edu\")\n",
        "\n",
        "print(\"My model's prediction:\", result)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "My model's prediction: Bachelors\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdLNA0ce1prd"
      },
      "source": [
        "### Part (f) [2 pt]\n",
        "\n",
        "What is the baseline model's prediction\n",
        "of this person's education level?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "TXgoM9qk1prd",
        "outputId": "827ee1da-75f2-492f-8792-3fda15af8ffa"
      },
      "source": [
        "print(\"Baseline model's prediction:\", mcv[\"edu\"])"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Baseline model's prediction:  HS-grad\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}